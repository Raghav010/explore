#!/bin/bash
# this script needs to be executed from this directory only!!

set -e

source .env


# make temp dir where dropbox photos will be pulled to
mkdir -p "${HOT1}temp"

# rclone pull to cloudstream
echo "< $(date +"%D %T") >--------------------------->pulling from dropbox..."
rclone copy "$REMOTENAME:$REMOTE_FOLDER" "${HOT1}temp"

# chronologize these
echo "< $(date +"%D %T") >--------------------------->chronologizing..."
cd chronologizer/src
python3 sortphotos.py -s -r --sort %Y%m "${HOT1}temp" "$HOT1$HOT_CLOUDSTREAM_NAME"
cd ../../
rm -rf "${HOT1}temp"

# copy these to other hot drives photos dir using backup 
echo "< $(date +"%D %T") >--------------------------->populating to other hot drives"
./backinUp/backup "$HOT1$HOT_CLOUDSTREAM_NAME" "$HOT2$HOT_PHOTOS_NAME"


# copy these to disc photos using backup
if [[ "$DISC_STOP" -eq 0 ]]
then
    echo "< $(date +"%D %T") >--------------------------->copying to discovery drive"
    ./backinUp/backup "$HOT1$HOT_CLOUDSTREAM_NAME" "${DISC}${DISC_PHOTOS_NAME}sampleDir/"
fi

# move these to curr hot drive downstream using backup
echo "< $(date +"%D %T") >--------------------------->moving to downstream of current hotdrive"
./backinUp/backup "$HOT1$HOT_CLOUDSTREAM_NAME" "$HOT1$HOT_DOWNSTREAM_NAME"
rm -r "${HOT1}${HOT_CLOUDSTREAM_NAME}"* || true


#if [[ "$DISC_STOP" -eq 0 ]]
#then
    # update home gallery import initial
#    sudo docker compose run -T gallery run import --update
#fi




# delete from dropbox using rclone
echo "< $(date +"%D %T") >--------------------------->deleting from dropbox"
rclone delete "$REMOTENAME:$REMOTE_FOLDER"



# check for space and buffer in hot and disc, set envs
echo "< $(date +"%D %T") >--------------------------->conducting discovery drive space checks"
freeDISC=$(df --block-size=1G "${DISC}" --output=avail | tail -1 | awk '{print $1}')
if [[ "$freeDISC" -le "$BUFFER_DISC" ]]
then
    cat .env | grep -v "DISC_STOP" > .env
    echo "DISC_STOP=1" >> .env
fi


